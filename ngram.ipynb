{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import time\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class NgramModel(object):\n",
    "\n",
    "    \"\"\"\n",
    "    Class init\n",
    "    :param 'n': number of words in n-gram\n",
    "    \"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        # dictionary that keeps list of candidate words given context\n",
    "        self.context = {}\n",
    "        # keeps track of how many times ngram has appeared in the text before\n",
    "        self.ngram_counter = {}\n",
    "\n",
    "    '''\n",
    "    Text tokenizer\n",
    "    :param 'text'   : Takes input sentence\n",
    "    :return         : tokenized sentence\n",
    "    '''\n",
    "    def tokenize(self, text: str) -> List[str]:\n",
    "        for punct in string.punctuation:\n",
    "            text = text.replace(punct, ' '+punct+' ')\n",
    "        t = text.split()\n",
    "        return t\n",
    "\n",
    "    \"\"\"\n",
    "    Get ngrams with tuple form\n",
    "    :param 'n'      : n-gram size\n",
    "    :param 'tokens' : tokenized sentence\n",
    "    :return         : list of ngrams\n",
    "    \"\"\"\n",
    "    def get_ngrams(self, n: int, tokens: list) -> list:\n",
    "        # tokens.append('<END>')\n",
    "        tokens = (n-1)*['<START>']+tokens\n",
    "        l = [(tuple([tokens[i-p-1] for p in reversed(range(n-1))]), tokens[i])\n",
    "             for i in range(n-1, len(tokens))]\n",
    "        return l\n",
    "\n",
    "    \"\"\"\n",
    "    Updates Language Model\n",
    "    :param 'sentence': input text\n",
    "    \"\"\"\n",
    "    def update(self, sentence: str) -> None:\n",
    "        n = self.n\n",
    "        ngrams = self.get_ngrams(n, self.tokenize(sentence))\n",
    "        for ngram in ngrams:\n",
    "            if ngram in self.ngram_counter:\n",
    "                self.ngram_counter[ngram] += 1.0\n",
    "            else:\n",
    "                self.ngram_counter[ngram] = 1.0\n",
    "\n",
    "            prev_words, target_word = ngram\n",
    "            if prev_words in self.context:\n",
    "                self.context[prev_words].append(target_word)\n",
    "            else:\n",
    "                self.context[prev_words] = [target_word]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    ":param 'n'      : number of words to be produced\n",
    ":param 'path'   : text file path\n",
    ":return         : generated text\n",
    "\"\"\"\n",
    "def create_ngram_model(n, path):\n",
    "    m = NgramModel(n)\n",
    "    with open(path, 'r') as f:\n",
    "        text = f.read()\n",
    "        text = text.split('.')\n",
    "        for sentence in text:\n",
    "            # add back the fullstop\n",
    "            sentence += '.'\n",
    "            m.update(sentence)\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculates probability of a candidate token to be generated given a context\n",
    ":param 'context':\n",
    ":param 'token'  :\n",
    ":return         : conditional probability\n",
    "\"\"\"\n",
    "def prob(self, context, token):\n",
    "    try:\n",
    "        count_of_token = self.ngram_counter[(context, token)]\n",
    "        count_of_context = float(len(self.context[context]))\n",
    "        result = count_of_token / count_of_context\n",
    "    except KeyError:\n",
    "        result = 0.0\n",
    "    return result\n",
    "\n",
    "\"\"\"\n",
    "Given a context we \"semi-randomly\" select the next word to append in a sequence\n",
    ":param 'context':\n",
    ":return         :\n",
    "\"\"\"\n",
    "def random_token(self, context):\n",
    "    r = random.random()\n",
    "    map_to_probs = {}\n",
    "    token_of_interest = self.context[context]\n",
    "    for token in token_of_interest:\n",
    "        map_to_probs[token] = self.prob(context, token)\n",
    "    summ = 0\n",
    "    for token in sorted(map_to_probs):\n",
    "        summ += map_to_probs[token]\n",
    "        if summ > r:\n",
    "            return token\n",
    "\n",
    "\n",
    "\"\"\"\n",
    ":param 'token_count': number of words to be produced\n",
    ":return             : generated text\n",
    "\"\"\"\n",
    "def generate_text(self, token_count: int):\n",
    "    n = self.n\n",
    "    context_queue = (n - 1) * ['<START>']\n",
    "    result = []\n",
    "    for _ in range(token_count):\n",
    "        obj = self.random_token(tuple(context_queue))\n",
    "        result.append(obj)\n",
    "        if n > 1:\n",
    "            context_queue.pop(0)\n",
    "            if obj == '.':\n",
    "                context_queue = (n - 1) * ['<START>']\n",
    "            else:\n",
    "                context_queue.append(obj)\n",
    "    return ' '.join(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Model creating time: 0.0067691802978515625\n",
      "('of',) {'the': 23, 'a': 1, 'elegance': 1, 'refined': 1, 'Tartu': 6, 'tourist': 1, 'government': 1, 'pink': 1, 'old': 2, 'these': 1, 'Toome': 2, 'Tartu’s': 3, 'mystery': 1, 'science': 1, 'this': 1, 'street': 1, 'buildings': 1, 'fun': 1, '19th': 1, 'Eduard': 1}\n",
      "('the',) {'capital': 1, 'only': 2, 'oldest': 4, '11th': 1, 'country’s': 1, 'city': 10, 'ever': 1, 'most': 3, 'centre': 5, 'heart': 1, 'city’s': 1, 'Emajõgi': 2, 'square': 1, 'beloved': 1, 'fountain': 1, 'Town': 2, 'local': 2, 'previous': 1, 'design': 1, 'least': 1, 'world': 1, 'country': 2, 'church': 1, '14th': 1, 'nearly': 1, 'viewing': 1, 'more': 2, 'Supilinn': 1, 'university': 1, '7th': 1, 'hill': 1, 'Angel’s': 1, 'first': 1, 'old': 1, '13th': 1, 'Livonian': 1, 'cathedral': 1, 'University': 2, 'history': 1, 'museum': 1, 'best': 5, 'beating': 1, 'University’s': 2, 'elegant': 1, 'grand': 1, 'university’s': 1, '19th': 1, 'main': 1, 'Old': 1, 'UNESCO': 1, 'creative': 1, 'strong': 1, 'sides': 1, 'period': 1, 'other': 1, 'gentle': 1, 'river': 1, 'light': 1, 'riverfront': 1, 'various': 1, 'Vilde': 1, 'acclaimed': 1, 'amazing': 1}\n",
      "('in',) {'Estonia': 2, 'the': 8, 'this': 2, 'Tartu': 6, '.': 1, '1789': 1, 'a': 1, '1632': 1, 'Old': 1, 'operation': 1, 'shuttered': 1, 'front': 1, 'its': 1, 'is': 1}\n",
      "(',',) {'Tallinn': 1, 'it’s': 3, 'Tartu': 4, 'is': 2, 'home': 1, 'the': 8, 'make': 1, 'which': 2, 'very': 1, 'and': 3, 'a': 4, 'newlyweds': 1, 'markets': 1, 'Raekoja': 1, 'built': 1, 'you': 1, 'but': 2, 'parts': 1, '000': 1, 'there’s': 1, 'this': 2, 'full': 1, 'has': 1, 'it': 2, 'making': 1, 'just': 1, 'these': 1, 'in': 1, 'to': 1, 'there': 1, 'locals': 1, 'many': 1, 'outside': 1, 'you’ll': 1, 'scientists': 1}\n",
      "('is',) {'a': 3, 'actually': 1, 'truly': 1, 'its': 1, 'no': 1, 'the': 7, 'St': 1, 'not': 1, 'being': 1, 'home': 2, 'also': 1, 'lined': 1, 'just': 1}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    n = 2\n",
    "    m = create_ngram_model(n, '10_Best_Things_to_Do_in_Tartu.txt')\n",
    "\n",
    "    print(f'Language Model creating time: {time.time() - start}')\n",
    "    start = time.time()\n",
    "\n",
    "    # calculate n-gram pop\n",
    "    sort_ngram_dict = dict(\n",
    "        sorted(m.ngram_counter.items(), key=lambda item: item[1], reverse=True)[:5])\n",
    "    for key, value in sort_ngram_dict.items():\n",
    "        # print(f'{key}:{value}')\n",
    "        word_dict = {}\n",
    "        for word in m.context[key[0]]:\n",
    "            if word in word_dict.keys():\n",
    "                word_dict[word] += 1\n",
    "            else:\n",
    "                word_dict[word] = 1\n",
    "        print(key[0], word_dict)\n",
    "    # print(f'{\"=\"*50}\\nGenerated text:')\n",
    "    # print(m.generate_text(50))\n",
    "    # print(f'{\"=\"*50}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "[1] [Text Generation Using N-Gram Model](https://towardsdatascience.com/text-generation-using-n-gram-model-8d12d9802aa0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
