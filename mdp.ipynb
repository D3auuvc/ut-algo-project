{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, ngrams\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class NgramModel(object):\n",
    "\n",
    "    def __init__(self, n=1):\n",
    "        \"\"\"\n",
    "        Class init\n",
    "        :param 'n': length of n-gram, default is one\n",
    "        \"\"\"\n",
    "        self.n = n\n",
    "        # a nested breakdown of all the words associated\n",
    "        # before and after the appearance of another word\n",
    "        self.entropylist = defaultdict(list)\n",
    "        # keeps track of how many times ngram has appeared in the text before\n",
    "        self.ngram_counter = {}\n",
    "\n",
    "    def get_ngrams(self, corpus: list) -> dict:\n",
    "        \"\"\"\n",
    "        Get ngrams\n",
    "        :param 'corpus' : contents want to process in ngram\n",
    "        :return         : list of ngrams\n",
    "        \"\"\"\n",
    "\n",
    "        # list of special characters want to be removed from the corpus.\n",
    "        removals = string.punctuation + '``'+'â€™'\n",
    "\n",
    "        for com in corpus:\n",
    "            ngram_statement = [str(i).lower() for i in ngrams(\n",
    "                [iter for iter in word_tokenize(com) if iter not in removals], self.n)]\n",
    "            counter = 0\n",
    "            recent_list = []\n",
    "            for gram in ngram_statement:\n",
    "\n",
    "                # Romovig formatting that applied to the string format\n",
    "                # when being passed through word_tokenize.\n",
    "                if self.n == 1:\n",
    "                    gram_clean = gram[2:len(gram)-3]\n",
    "                else:\n",
    "                    gram_clean = ''.join(gram)\n",
    "\n",
    "                # Depending on the position and length of the gram\n",
    "                if counter == 0:\n",
    "                    self.entropylist['[start]'].append(gram_clean)\n",
    "                    recent_list.append(gram_clean)\n",
    "                elif counter > 0:\n",
    "                    self.entropylist[str(\n",
    "                        recent_list[len(recent_list)-self.n])].append(str(gram_clean))\n",
    "                    recent_list.append(gram_clean)\n",
    "                elif counter == len(ngram_statement):\n",
    "                    self.entropylist[str(\n",
    "                        recent_list[len(recent_list)-self.n])].append('[end]')\n",
    "                    recent_list.append('[end]')\n",
    "\n",
    "                counter += 1\n",
    "\n",
    "        # usage count represents the appearance\n",
    "        # of words (in their respective order)\n",
    "        for key in self.entropylist:\n",
    "            count_vals = {}\n",
    "            # increment the appearance of the grams that appear within the gram.\n",
    "            for val in self.entropylist[key]:\n",
    "                if str(val) in count_vals:\n",
    "                    count_vals[str(val)] += 1\n",
    "                else:\n",
    "                    count_vals[str(val)] = 1\n",
    "\n",
    "            self.ngram_counter[str(val)] = [count_vals]\n",
    "\n",
    "        return {'usage': self.ngram_counter, 'entropylist': self.entropylist}\n",
    "\n",
    "\n",
    "class MarkovChainModel(object):\n",
    "\n",
    "    def __init__(self, ngrams):\n",
    "        \"\"\"\n",
    "        Class init\n",
    "        :param 'ngrams': data structure of the n-gram\n",
    "        \"\"\"\n",
    "\n",
    "        self.ngrams = ngrams\n",
    "\n",
    "    def _transition_table(self) -> dict:\n",
    "        \"\"\"\n",
    "        Returns the set of transition tables based on the length of n\n",
    "        :return : set of transition table(s)\n",
    "        \"\"\"\n",
    "\n",
    "        all_entropy = {}\n",
    "        ngrams = self.ngrams\n",
    "\n",
    "        for key in ngrams['entropylist']:\n",
    "            cond_prob_val = {}\n",
    "            relative_usage = Counter(ngrams['entropylist'][key])\n",
    "            relative_words_len = sum(relative_usage.values())\n",
    "\n",
    "            for following_gram in relative_usage:\n",
    "                cond_prob_val[following_gram] = float(\n",
    "                    relative_usage[following_gram]) / float(relative_words_len)\n",
    "\n",
    "            all_entropy[key] = cond_prob_val\n",
    "\n",
    "        return all_entropy\n",
    "\n",
    "    def _melt_transition_table(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create a melted dataframe\n",
    "        :return : dataframe of transition table(s)\n",
    "        \"\"\"\n",
    "\n",
    "        transition_table = self._transition_table()\n",
    "        flat_output = []\n",
    "        for key in transition_table:\n",
    "            for foll in transition_table[key]:\n",
    "                temp_row = [key, foll, transition_table[key][foll]]\n",
    "                flat_output.append(temp_row)\n",
    "        pd_flat = pd.DataFrame(flat_output)\n",
    "        headers = ['parent', 'relation', 'percentage']\n",
    "        pd_flat.columns = headers\n",
    "        # pd_flat.to_csv('output.csv')\n",
    "        return pd_flat\n",
    "\n",
    "    def get_matrix(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create a markov chain transition matrix\n",
    "        :return : transition matrix of markov chain\n",
    "        \"\"\"\n",
    "        transition_table = self._melt_transition_table()\n",
    "\n",
    "        distinct = (list(set(transition_table['parent'].unique())\n",
    "                    | set(transition_table['relation'].unique())))\n",
    "        zero_data = np.zeros(shape=(len(distinct), len(distinct)))\n",
    "        df = pd.DataFrame(index=distinct, columns=distinct, data=zero_data)\n",
    "        for _, row in transition_table.iterrows():\n",
    "            df[row['parent']][row['relation']] = row['percentage']\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus(path: str) -> list:\n",
    "    \"\"\"\n",
    "    Get corpus from the path file\n",
    "    :param 'path'   : corpus file path\n",
    "    :return         : generated corpus\n",
    "    \"\"\"\n",
    "    corpus = ''\n",
    "    with open(path, mode='r', encoding='utf8') as f:\n",
    "        corpus = f.readlines()\n",
    "        corpus = [s.rstrip('\\n') for s in corpus]\n",
    "\n",
    "    return corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strassen_algorithm(matrix, c_word, k):\n",
    "    \"\"\"\n",
    "    Execute Markov chain to get the probability of the word come after current word\n",
    "    :param 'matrix' : transition matrix of markov chain\n",
    "    :param 'c_word' : current word\n",
    "    :param 'k'      : the probability of k+1-th word comes after k-th word\n",
    "    :return : probability of the next word\n",
    "    \"\"\"\n",
    "    if k == 1:\n",
    "        return matrix[c_word]\n",
    "    else:\n",
    "        res = pd.DataFrame(data=np.identity(len(matrix.index)),\n",
    "                           index=matrix.index, columns=matrix.columns)\n",
    "        for _ in range(k):\n",
    "            res = res.dot(matrix)\n",
    "        return res[c_word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "def sparse_matrix_multiplication(matrix, c_word, k):\n",
    "    mat = csr_matrix(matrix.to_numpy())\n",
    "    if k == 1:\n",
    "        return matrix[c_word]\n",
    "    else:\n",
    "        res = csr_matrix(np.identity(len(matrix.index)))\n",
    "        for _ in range(k):\n",
    "            res = res.dot(mat)\n",
    "            # res = res@matrix\n",
    "        res = pd.DataFrame(data=res.todense(),\n",
    "                           index=matrix.index, columns=matrix.columns)\n",
    "        return res[c_word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult(A, B):\n",
    "    result = []  # final result\n",
    "    for i in range(len(A)):\n",
    "        row = []  # the new row in new matrix\n",
    "        for j in range(len(B[0])):\n",
    "            product = 0  # the new element in the new row\n",
    "            for v in range(len(A[i])):\n",
    "                product += B[i][v] * A[v][j]\n",
    "            row.append(product)  # append sum of product into the new row\n",
    "        result.append(row)  # append the new row into the final result\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regular_matrix_multiplication(matrix, c_word, k):\n",
    "    if k == 1:\n",
    "        return matrix[c_word]\n",
    "    else:\n",
    "        A = list(matrix.to_numpy())\n",
    "        res = list(np.identity(len(matrix.index)))\n",
    "        for _ in range(k):\n",
    "            res = mult(res, A)\n",
    "        res = pd.DataFrame(data=np.array(\n",
    "            res), index=matrix.index, columns=matrix.columns)\n",
    "        return res[c_word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_model = NgramModel()\n",
    "path = r'Pride_and_Prejudice.txt'\n",
    "corpus = get_corpus(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_len = [50,100,150,200,250,300,350,400,450,500]\n",
    "strassen_rt = []\n",
    "sparse_rt = []\n",
    "regular_rt = []\n",
    "\n",
    "for n in n_len:\n",
    "    markov_model = MarkovChainModel(ngram_model.get_ngrams(corpus[:n]))\n",
    "    matrix = markov_model.get_matrix()\n",
    "    \n",
    "    strassen_start = time.time()\n",
    "    guess_word_1 = strassen_algorithm(matrix, 'universally', 3)\n",
    "    strassen_rt.append(time.time() - strassen_start)\n",
    "    # print(f'Language Model creating time with Strassen algorithm: {time.time() - start}')\n",
    "\n",
    "    sparse_start = time.time()\n",
    "    guess_word_2 = sparse_matrix_multiplication(matrix, 'universally', 3)\n",
    "    sparse_rt.append(time.time() - sparse_start)\n",
    "    # print(f'Language Model creating time with Sparse matrix algorithm: {time.time() - start}')\n",
    "\n",
    "    regular_start = time.time()\n",
    "    guess_word_2 = regular_matrix_multiplication(matrix, 'universally', 3)\n",
    "    regular_rt.append(time.time() - regular_start)\n",
    "    print(f'The count of words: {n}')\n",
    "    # print(f'Language Model creating time with Sparse matrix algorithm: {time.time() - start}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(strassen_rt)\n",
    "print(sparse_rt)\n",
    "print(regular_rt)\n",
    "\n",
    "plt.grid()\n",
    "plt.title(\"Markov Chain with different matrix multiplications\")\n",
    "plt.xlabel(\"The wordcount\")\n",
    "plt.ylabel(\"The runtime\")\n",
    "\n",
    "plt.plot(n_len, strassen_rt, 'g', label = 'Strassen matrix multiplication')\n",
    "plt.plot(n_len, sparse_rt, 'r', label = 'Sparse matrix multiplication')\n",
    "plt.plot(n_len, regular_rt, 'b', label = 'Regular matrix multiplication')\n",
    "plt.legend()\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 8)\n",
    "plt.show()\n",
    "plt.savefig('time-comparision-all.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_len, strassen_rt, 'g', label = 'Strassen matrix multiplication')\n",
    "plt.plot(n_len, sparse_rt, 'r', label = 'Sparse matrix multiplication')\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 8)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(\"Markov Chain with different matrix multiplications\")\n",
    "plt.xlabel(\"The wordcount\")\n",
    "plt.ylabel(\"The runtime\")\n",
    "plt.show()\n",
    "plt.savefig('time-comparision-sparse-strassen.png')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "408d296dac86e32f9a39c3b342851e7f5d0e2324398d48fdd8d12907187dd98b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
