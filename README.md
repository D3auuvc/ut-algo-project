# N-gram Modeling with Markov Transition for Classify Text

**Idea Description:** To reduce the complexity of n-gram model, this project tries to implement the Markov Transition by storing the probabilities of transitioning to a next state.

**Motivation and the Main Challenge:** For NLP, we have to pre-process text (e.g., NER) to create useful dataset for model, however, usually it will take a lot of time for data preparation. Hence, we try to build a method for NER. Usually meaning of word will be decided by context, so word in open domain will be the challenge.
